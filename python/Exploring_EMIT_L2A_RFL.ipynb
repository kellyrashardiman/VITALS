{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# EMIT L2A Reflectance Fundamentals\n",
    "\n",
    "**Summary**    \n",
    "\n",
    "This notebook will explain how to access Earth Surface Mineral Dust Source Investigation (EMIT) data programmatically using the [earthaccess Python library](https://github.com/nsidc/earthaccess). `earthaccess` is a useful Python library that facilitates finding and downloading or streaming data over HTTPS or s3. `earthaccess` searches NASA's Common Metadata Repository (CMR), a metadata system that catalogs Earth Science data and associated metadata records, then can be used to download granules or generate lists of granule search result URLs.  After accessing the data, we will open visualize the [EMIT L2A Reflectance Data (EMITL2ARFL)](https://doi.org/10.5067/EMIT/EMITL2ARFL.001), and extract spectral values for a series of points using an interactive plot.\n",
    "\n",
    "<div>\n",
    "<img src=\"../img/emit-fundamentals.png\" width=\"750\"/>\n",
    "</div>\n",
    "\n",
    "**Background**\n",
    "\n",
    "The EMIT instrument is an imaging spectrometer that measures light in visible and infrared wavelengths. These measurements display unique spectral signatures that correspond to the composition on the Earth's surface. The EMIT mission focuses specifically on mapping the composition of minerals to better understand the effects of mineral dust throughout the Earth system and human populations now and in the future. More details about EMIT and its associated products can be found in the **README.md** and on the [EMIT website](https://earth.jpl.nasa.gov/emit/).\n",
    "\n",
    "The L2A Reflectance Product contains estimated surface reflectance. Surface reflectance is the fraction of incoming solar radiation reflected Earth's surface. Materials reflect proportions of radiation differently based upon their chemical composition.  This means that reflectance information can be used to determine the composition of a target. In this guide you will learn how to plot a band from the L2A reflectance spatially and look at the spectral curve associated with individual pixels.\n",
    "\n",
    "**Requirements**  \n",
    "\n",
    "- A NASA [Earthdata Login](https://urs.earthdata.nasa.gov/) account is required.   \n",
    "\n",
    "**Learning Objectives**  \n",
    "\n",
    "- How to find EMIT data using `earthaccess`\n",
    "- How to open an EMIT `.nc` file as an `xarray.Dataset`\n",
    "- How to work with EMIT L2A Reflectance data\n",
    "- How to mask and quality filter EMIT L2A Reflectance data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import the required Python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "import math\n",
    "import csv\n",
    "import earthaccess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rioxarray as rxr\n",
    "import xarray as xr\n",
    "import hvplot.xarray\n",
    "import holoviews as hv\n",
    "import geoviews as gv\n",
    "import cartopy.crs as ccrs\n",
    "from modules.emit_tools import emit_xarray, ortho_xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we we are importing a local module for handling EMIT data called `emit_tools`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authentication\n",
    "\n",
    "`earthaccess` creates and leverages Earthdata Login tokens to authenticate with NASA systems. Earthdata Login tokens expire after a month. To retrieve a token from Earthdata Login, you can either enter your username and password each time you use `earthaccess`, or use a `.netrc` file. A `.netrc` file is a configuration file that is commonly used to store login credentials for remote systems. If you don't have a `.netrc` or don't know if you have one or not, you can use the `persist` argument with the `login` function below to create or update an existing one, then use it for authentication.\n",
    "\n",
    "If you do not have an Earthdata Account, you can create one [here](https://urs.earthdata.nasa.gov/home)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = earthaccess.login(persist=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching for Collections\n",
    "\n",
    "The EMIT mission produces several collections or datasets available via the NASA Earthdata cloud archive. \n",
    "\n",
    "To view what's available, we can use the `search_datasets` function and with the `keyword` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve Collections\n",
    "collections = earthaccess.search_datasets(keyword='EMIT')\n",
    "# Print Quantity of Results\n",
    "print(f'Collections found: {len(collections)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you print the `collections` object you can explore all of the json metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print collections\n",
    "# collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create a list of the `short-name`, `concept-id`, and `version` of each result collection using list comprehension. These fields are important for specifying and searching for data within collections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collections_info = [\n",
    "    {\n",
    "        'short_name': c.summary()['short-name'],\n",
    "        'collection_concept_id': c.summary()['concept-id'],\n",
    "        'version': c.summary()['version'],\n",
    "        'entry_title': c['umm']['EntryTitle']\n",
    "    }\n",
    "    for c in collections\n",
    "]\n",
    "pd.set_option('display.max_colwidth', 150)\n",
    "collections_info = pd.DataFrame(collections_info)\n",
    "collections_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The collection `concept-id` is the best way to search for data within a collection, as this is unique to each collection. The `short-name` can be used as well, however the `version` should be passed as well as there can be multiple versions available with the same short name. After finding the collection you want to search, you can use the `concept-id` to search for granules within that collection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching for Granules\n",
    "\n",
    "A `granule` can be thought of as a unique spatiotemporal grouping within a collection. To search for `granules`, we can use the `search_data` function from `earthaccess` and provide the arguments for our search. Its possible to specify search products using several criteria shown in the table below:\n",
    "\n",
    "|dataset origin and location|spatio temporal parameters|dataset metadata parameters|\n",
    "|:---|:---|:---|\n",
    "|archive_center|bounding_box|concept_id\n",
    "|data_center|temporal|entry_title\n",
    "|daac|point|granule_name\n",
    "|provider|polygon|version\n",
    "|cloud_hosted|line|short_name\n",
    "\n",
    "For this example we will search for the **EMIT L2A Surface Reflectance** using a bounding box, temporal parameters, and add a `cloud_cover` parameter. Note that not all datasets have cloud cover information in their metadata, so this parameter may not work for all datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boulder CO Area Bounding Box\n",
    "bbox = (-105.301, 39.957, -105.178, 40.094)\n",
    "bbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass the **bbox** Python variable to the `bounding_box` argument, then enter a start and end date for the `temporal argument` minimum and maximum `cloud_cover` as Python tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = earthaccess.search_data(\n",
    "    short_name='EMITL2ARFL',\n",
    "    bounding_box=bbox,\n",
    "    temporal=('2023-06-01','2023-09-30'),\n",
    "    cloud_cover=(0,50)\n",
    ")\n",
    "print(f\"Granules Found: {len(results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can preview our results by printing a single one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `data_links()` convenience function to extract the data links for all of the granules. In this case there are multiple files associated with a single granule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emit_results_urls = [granule.data_links(access=\"external\") for granule in results]\n",
    "emit_results_urls[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flatten our list of lists into a single list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = [url for urls in emit_results_urls for url in urls]\n",
    "url_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with EMIT Data\n",
    "\n",
    "EMIT collections and their associated granules are archived and distributed from NASA's Earthdata Cloud. Because of this, data assets/files can be accessed in a variety of ways. Data distributed from Earthdata Cloud can be:\n",
    "\n",
    "**Downloaded** – This has been a supported option since the inception of NASA's DAACs. Users can use the data link(s) to download files to their local working environment. This method works in both cloud and non-cloud environments.\n",
    "\n",
    "**Streamed** – Streaming enables on-the-fly reading of remote files (i.e., files not saved locally). However, the accessed data must fit into the workspace’s memory. Streaming works in both cloud and non-cloud environments. Streaming data stored in the cloud without downloading is called **in-place access or direct S3 access**. this is only available when working in a cloud environment deployed in AWS us-west-2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Downloading Data**  \n",
    "\n",
    "The `download()` function from `earthaccess` can be used to efficiently download the data links from a `earthaccess` search results. A list of URLs can also be passed to the function. The convenient part of using the `download()` function is that authentication is taken care of on behalf of the user.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download `earthaccess` search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# earthaccess.download(results, local_path='../data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download from URL list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#earthaccess.download(url_list, local_path='../data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Streaming Data**  \n",
    "\n",
    "Data in NASA Earthdata Cloud can be read into the workspace by streaming the data, that is, no download is required. Here we will assign a single URL for EMIT *reflectance* and for the *mask* layer from our **url_list** to read in and explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emit_rfl = url_list[0]\n",
    "emit_rfl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emit_qa = url_list[2]\n",
    "emit_qa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access data from NASA, you'll need to provide your Earthdata Login credentials. When streaming this can best be done using the token or cookies set up by the `earthaccess` library. Since we've already logged in, we can start an `fsspec` session to manage our connection to a remote file, including sending credentials. This allows other libraries to work with a URL as if it is a local file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get HTTPS Session using Earthdata Login Info\n",
    "fs = earthaccess.get_fsspec_https_session()\n",
    "\n",
    "# Use the session (i.e., fs) to connect to the file\n",
    "emit_fp = fs.open(emit_rfl)\n",
    "emit_qa_fp = fs.open(emit_qa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have an authenticated connection to the data links. We can now start exploring these data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening and Exploring EMIT Reflectance Data\n",
    "\n",
    "EMIT L2A Reflectance Data are distributed in a non-orthocorrected spatially raw NetCDF4 (.nc) format consisting of the data and its associated metadata. Inside the L2A Reflectance `.nc` file there are 3 groups. Groups can be thought of as containers to organize the data. \n",
    "\n",
    "1. The root group that can be considered the main dataset contains the reflectance data described by the downtrack, crosstrack, and bands dimensions.  \n",
    "2. The `sensor_band_parameters`  group containing the wavelength center and the full-width half maximum (FWHM) of each band.  \n",
    "3. The `location` group contains latitude and longitude values at the center of each pixel described by the crosstrack and downtrack dimensions, as well as a geometry lookup table (GLT) described by the ortho_x and ortho_y dimensions. The GLT is an orthorectified image (EPSG:4326) consisting of 2 layers containing downtrack and crosstrack indices. These index positions allow us to quickly project the raw data onto this geographic grid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To work with the EMIT data, we will use the `emit_tools` module. There are other ways to work with the data and a more thorough explanation of the `emit_tools` in the [EMIT-Data-Resources Repository](https://github.com/nasa/EMIT-Data-Resources).\n",
    "\n",
    "Open the example EMIT scene using the `emit_xarray` function. In this step we will use the `ortho=False` argument (default) read in the data in its source non-orthocorrected form. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the data to speed up future cells\n",
    "emit_ds = emit_xarray(emit_fp, ortho=False).load()\n",
    "emit_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the **wavelengths** coordinate variable is indexed, we can use `sel()` functions to filter for specific wavelength values from our EMIT datacube, then visualize using `hvplot.image()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a band @ 850nm\n",
    "rfl_850 = emit_ds['reflectance'].sel(wavelengths=850, method='nearest')\n",
    "# Plot - Note we flip the y axis, so (0,0) is top left corner\n",
    "rfl_850.hvplot.image(cmap='viridis',\n",
    "                        aspect='equal',\n",
    "                        frame_height=405, \n",
    "                        fontscale=2).opts(title=f\"{rfl_850.wavelengths:.3f} {rfl_850.wavelengths.units}\", invert_yaxis=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the orientation of the plotted image. Remember this is not orthocorrected and thus is not north up. You may notice that EMIT radiance and reflectance scenes rows of missing data in some scenes. This is due to EMIT's on-board cloud filtering. Additionally, filtering can be applied using the **mask** layer (example later in this exercise)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an orthocorrected image of our data using the `ortho_xr()` function from the `emit_tools` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emit_ds = ortho_xr(emit_ds)\n",
    "emit_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the orthorectification process we introduce fill values (-9999). To make a better visual, we can assign these to `np.nan`. At the same time we can also utilize the `good_wavelengths` flag from the `sensor_band_parameters` group to mask out bands where water absorption features were assigned a value of -0.01 reflectance. Typically data around 1320-1440 nm and 1770-1970 nm are noisy due to the moisture present in the atmosphere; therefore, these spectral regions offer little information about targets and can be excluded from calculations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emit_ds['reflectance'].data[:,:,emit_ds['good_wavelengths'].data==0] = np.nan\n",
    "emit_ds['reflectance'].data[emit_ds['reflectance'].data == -9999] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Band\n",
    "rfl_850 = emit_ds['reflectance'].sel(wavelengths=850, method='nearest')\n",
    "# Plot\n",
    "rfl_850.hvplot.image(cmap='viridis',\n",
    "                        geo=True, \n",
    "                        tiles='ESRI', \n",
    "                        crs='EPSG:4326', \n",
    "                        frame_width=720,\n",
    "                        frame_height=405, \n",
    "                        alpha=0.7, \n",
    "                        fontscale=2).opts(title=f\"{rfl_850.wavelengths:.3f} {rfl_850.wavelengths.units}\",\n",
    "                        xlabel='Longitude',ylabel='Latitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a orthorectified image that is north up! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Spectra  \n",
    "\n",
    "Similar to selecting a wavelength, we can select the spectra of an individual pixel closest to a specified latitude and longitude we want using the `sel` function from `xarray`. First grab the center coordinates of the scene to use as an example.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve center pixel coordinates\n",
    "scene_center = emit_ds.latitude.values[int(len(emit_ds.latitude)/2)],emit_ds.longitude.values[int(len(emit_ds.longitude)/2)]\n",
    "scene_center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now select and plot using `hvplot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract a single point\n",
    "point = emit_ds.sel(latitude=scene_center[0],longitude=scene_center[1], method='nearest')\n",
    "# Plot\n",
    "point.hvplot.line(y='reflectance', \n",
    "                  x='wavelengths', \n",
    "                  color='black').opts(title=f'Latitude = {point.latitude.values.round(3)}, Longitude = {point.longitude.values.round(3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot individual bands spatially by selecting a wavelength, then plotting. Select the band with a wavelengths of 850 nm and plot it using ESRI imagery as a basemap to get a better understanding of where the scene was acquired. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Quality Masks to EMIT Data\n",
    "\n",
    "The EMIT L2A Mask file contains some bands that are direct masks (Cloud, Dilated, Cirrus, Water, Spacecraft), and some (AOD550 and H2O (g cm-2)) that contain information calculated during the L2A reflectance retrieval. These may be used as additional screening, depending on the application.\n",
    "\n",
    "> Note: It is more memory efficient to apply the mask before orthorectifying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emit_mask = emit_xarray(emit_qa_fp, ortho=True)\n",
    "emit_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the quality flags contained in the `mask_bands` dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emit_mask.mask_bands.data.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned, we will use the `Dilated Cloud Flag`. Select that band with the `sel` function as we did for wavelengths before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emit_cloud_mask = emit_mask.sel(mask_bands='Dilated Cloud Flag')\n",
    "# mask fill values\n",
    "emit_cloud_mask['mask'].data[emit_cloud_mask['mask'].data == -9999] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can visualize our aggregate quality mask. You may have noticed before that we added a lot of parameters to our plotting function. If we want to consistently apply the same formatting for multiple plots, we can add those arguments to a dictionary that we can unpack into `hvplot` functions using `**`.\n",
    "\n",
    "Create two dictionaries with plotting options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "size_opts = dict(frame_height=405, frame_width=720, fontscale=2)\n",
    "map_opts = dict(geo=True, crs='EPSG:4326', alpha=0.7, xlabel='Longitude',ylabel='Latitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emit_cloud_mask.hvplot.image(cmap='viridis', tiles='ESRI', **size_opts, **map_opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values of 1 in the mask indicate areas to omit. Apply the mask to our EMIT Data by assigning values where the `mask.data == 1` to `np.nan`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emit_ds.reflectance.data[emit_cloud_mask.mask.data == 1] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can confirm our masking worked with a spatial plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emit_layer_filtered_plot = emit_ds.sel(wavelengths=850, method='nearest').hvplot.image(cmap='viridis',tiles='ESRI',**size_opts, **map_opts)\n",
    "emit_layer_filtered_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Spectral/Spatial Plots\n",
    "\n",
    "Combining the Spatial and Spectral information into a single visualization can be a powerful tool for exploring and inspecting imaging spectroscopy data. Using the streams module from Holoviews we can link a spatial map to a plot of spectra.\n",
    "\n",
    "We could plot a single band image as we previously have, but using a multiband image, like an RGB may help infer what targets we're examining. Build an RGB image following the steps below.\n",
    "\n",
    "Select bands to represent red (650 nm), green (560 nm), and blue (470 nm) by finding the nearest to a wavelength chosen to represent that color.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emit_rgb = emit_ds['reflectance'].sel(wavelengths=[650, 560, 470], method='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may need to adjust balance the brightness of the selected wavelengths to make a prettier map. **This will not affect the data, just the visuals.** To do this we will use the function below. We can change the `bright` argument to increase or decrease the brightness of the scene as a whole. A value of 0.2 usually works pretty well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gamma_adjust(rgb_da, bright=0.3):\n",
    "    \"\"\"\n",
    "    Adjust gamma across all bands in the RGB dataset.\n",
    "    \"\"\"\n",
    "    array = rgb_da.data\n",
    "    # Mask nan and negative values\n",
    "    invalid = np.isnan(array) | (array < 0)\n",
    "    valid = ~invalid\n",
    "\n",
    "    # Calculate gamma based on the mean of valid values\n",
    "    mean_valid = np.nanmean(array[valid])\n",
    "    gamma = math.log(bright) / math.log(mean_valid)\n",
    "    # Apply scaling and clip\n",
    "    scaled = np.full_like(array, np.nan)\n",
    "    scaled[valid] = np.power(array[valid], gamma)\n",
    "    rgb_da.data = np.clip(scaled, 0, 1)\n",
    "    return rgb_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emit_rgb = gamma_adjust(emit_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have an RGB dataset, we can use that to create a spatial plot, and data selected by clicking on that 'map' can be inputs for a function to return values from the full dataset at that latitude and longitude location using the cell below. To visualize the spectral and spatial data side-by-side, we use the Point Draw tool from the holoviews library.\n",
    "\n",
    "Define a limit to the quantity of points and spectra we will plot, a list of colors to cycle through, and an initial point. Then use the input from the Tap function to provide clicked x and y positions on the map and use these to retrieve spectra from the dataset at those coordinates.\n",
    "\n",
    "Click in the RGB image to add spectra to the plot. You can also click and hold the mouse button then drag previously placed points. To remove a point click and hold the mouse button down, then press the backspace key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive Spectral/Spatial Plotting\n",
    "# Modified from https://github.com/auspatious/hyperspectral-notebooks/blob/main/03_EMIT_Interactive_Points.ipynb\n",
    "\n",
    "# Starting Point from center pixel\n",
    "x_start = scene_center[1]\n",
    "y_start = scene_center[0]\n",
    "\n",
    "# Set Point Limit\n",
    "POINT_LIMIT = 10\n",
    "\n",
    "# Set up Color Cycling\n",
    "color_cycle = hv.Cycle('Category20')\n",
    "\n",
    "# Define initial point and spatial plot\n",
    "first_point = ([x_start], [y_start], [0])\n",
    "points = gv.Points(first_point, kdims=['longitude','latitude'], vdims='id', crs=ccrs.PlateCarree())\n",
    "\n",
    "# Define Point Draw Plot\n",
    "points_stream = hv.streams.PointDraw(\n",
    "    data=points.columns(),\n",
    "    source=points,\n",
    "    drag=True,\n",
    "    num_objects=POINT_LIMIT,\n",
    "    styles={'fill_color': color_cycle.values[:POINT_LIMIT], 'line_color': 'gray'}\n",
    ")\n",
    "\n",
    "# RGB Plot without Basemap\n",
    "rgb_map = emit_rgb.hvplot.rgb(x='longitude', y='latitude', bands='wavelengths',\n",
    "                            frame_height=480, frame_width=480,\n",
    "                            crs=ccrs.PlateCarree(),\n",
    "                            title=\"Stretched RGB EMIT Image\")\n",
    "# Set up tap and point streams\n",
    "posxy = hv.streams.PointerXY(source=rgb_map, x=x_start, y=y_start)\n",
    "clickxy = hv.streams.Tap(source=rgb_map, x=x_start, y=y_start)\n",
    "\n",
    "# Function to build spectral plot of clicked location to show on hover stream plot\n",
    "def click_spectra(data):\n",
    "    coordinates = [c for c in zip(data['longitude'], data['latitude'])]\n",
    "    \n",
    "    plots = {}\n",
    "    for i, coords in enumerate(coordinates):\n",
    "        x, y = coords\n",
    "        selected = emit_ds['reflectance'].sel(longitude=x, latitude=y, method=\"nearest\")\n",
    "        plots[i] = (\n",
    "            selected.hvplot.line(\n",
    "                y=\"reflectance\",\n",
    "                x=\"wavelengths\",\n",
    "                label=f\"{i}\"\n",
    "            )\n",
    "        )\n",
    "        points_stream.data[\"id\"][i] = i\n",
    "    return hv.NdOverlay(plots).opts(hv.opts.Curve(color=color_cycle))\n",
    "    \n",
    "# Function to provide hover spectra\n",
    "def hover_spectra(x,y):\n",
    "    return emit_ds['reflectance'].sel(longitude=x,latitude=y,method='nearest').hvplot.line(y='reflectance',x='wavelengths',\n",
    "                                                                           color='black', frame_width=480)\n",
    "# Define the Dynamic Maps\n",
    "click_dmap = hv.DynamicMap(click_spectra, streams=[points_stream])\n",
    "hover_dmap = hv.DynamicMap(hover_spectra, streams=[posxy])\n",
    "\n",
    "# Plot the Map and Dynamic Map side by side\n",
    "hv.Layout(hover_dmap*click_dmap + rgb_map * points).cols(2).opts(\n",
    "    hv.opts.Points(active_tools=['point_draw'], size=10, tools=['hover'], color='white', line_color='gray'),\n",
    "    hv.opts.Overlay(show_legend=False, show_title=False, fontscale=1.5, frame_height=480)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take these selected points and the corresponding reflectance spectra and save them as a `.csv` for later use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a dictionary of the selected points and spectra, then export the spectra to a .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = points_stream.data\n",
    "wavelengths = emit_ds.wavelengths.values\n",
    "\n",
    "rows = [[\"id\", \"longitude\", \"latitude\"] + [str(i) for i in wavelengths]]\n",
    " \n",
    "for p in zip(data['longitude'], data['latitude'], data['id']):\n",
    "    x, y, i = p\n",
    "    spectra = emit_ds.sel(longitude=x, latitude=y, method=\"nearest\").reflectance.values\n",
    "    row = [i, x, y] + list(spectra)\n",
    "    rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write points to csv\n",
    "with open('../data/emit_click_data.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contact Info:  \n",
    "\n",
    "Email: LPDAAC@usgs.gov  \n",
    "Voice: +1-866-573-3222  \n",
    "Organization: Land Processes Distributed Active Archive Center (LP DAAC)¹  \n",
    "Website: <https://www.earthdata.nasa.gov/centers/lp-daac>  \n",
    "\n",
    "¹Work performed under USGS contract 140G0121D0001 for NASA contract NNG14HH33I. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lpdaac_vitals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
